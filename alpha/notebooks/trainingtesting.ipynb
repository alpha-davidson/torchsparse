{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539332c8-f0d7-4d6e-a6f5-38e5398c6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "import os.path\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch.cuda import amp\n",
    "    \n",
    "import torchsparse\n",
    "from torchsparse import SparseTensor\n",
    "from torchsparse import nn as spnn\n",
    "from torchsparse.utils.collate import sparse_collate, sparse_collate_fn\n",
    "from torchsparse.utils.quantize import sparse_quantize\n",
    "from torch.cuda import amp\n",
    "from typing import Any, Dict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40a0c82-642c-4c65-ad57-8ddf9b895adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, coords, feats, labels):\n",
    "        coords = torch.tensor(coords, dtype=torch.int)\n",
    "        feats = torch.tensor(feats, dtype=torch.float)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.coords = coords\n",
    "        self.feats = feats\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.coords[idx], self.feats[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1053e1e0-a56d-447e-b4b9-e5ee77f00573",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "datetime_str = now.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "ISOTOPE = \"Mg22\"\n",
    "coords_train = np.load('../mg22simulated/' + ISOTOPE + \"_coords_train.npy\")\n",
    "coords_val = np.load('../mg22simulated/' + ISOTOPE + \"_coords_val.npy\")\n",
    "coords_test = np.load('../mg22simulated/' + ISOTOPE + \"_coords_test.npy\")\n",
    "feats_train = np.load('../mg22simulated/' + ISOTOPE + \"_feats_train.npy\")\n",
    "feats_val = np.load('../mg22simulated/' + ISOTOPE + \"_feats_val.npy\")\n",
    "feats_test = np.load('../mg22simulated/' + ISOTOPE + \"_feats_test.npy\")\n",
    "labels_train = np.load('../mg22simulated/' + ISOTOPE + \"_labels_train.npy\")\n",
    "labels_val = np.load('../mg22simulated/' + ISOTOPE + \"_labels_val.npy\")\n",
    "labels_test = np.load('../mg22simulated/' + ISOTOPE + \"_labels_test.npy\")\n",
    "\n",
    "coords_train = coords_train[0:100]\n",
    "feats_train = feats_train[0:100]\n",
    "labels_train = labels_train[0:100]\n",
    "\n",
    "coords_val = coords_val[0:50]\n",
    "feats_val = feats_val[0:50]\n",
    "labels_val = labels_val[0:50]\n",
    "\n",
    "coords_test = coords_test[0:50]\n",
    "feats_test = feats_test[0:50]\n",
    "labels_test = labels_test[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a05109-7e1e-4d04-ac8b-9b918e355697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Settings\n",
    "device = 'cuda'\n",
    "amp_enabled = True\n",
    "\n",
    "model = nn.Sequential(\n",
    "    spnn.Conv3d(4, 32, 3),\n",
    "    spnn.BatchNorm(32),\n",
    "    spnn.ReLU(True),\n",
    "    spnn.Conv3d(32, 32, 3),\n",
    "    spnn.BatchNorm(32),\n",
    "    spnn.ReLU(True),\n",
    "    spnn.Conv3d(32, 5, 1),\n",
    ").to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scaler = amp.GradScaler(enabled=amp_enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c9a120-446b-4e0d-8b90-31b652d81006",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 12\n",
    "\n",
    "train_set = CustomDataset(coords_train, feats_train, labels_train)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "\n",
    "val_set = CustomDataset(coords_val, feats_val, labels_val)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "\n",
    "test_set = CustomDataset(coords_test, feats_test, labels_test)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "train_steps = len(train_loader)\n",
    "val_steps = len(val_loader)\n",
    "\n",
    "test_len = len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2213d514-798c-42eb-92a7-1025e0ce3fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Running Loss: 1.531373593542311\n",
      "[Epoch 1] Validation Loss: 1.7237628698349\n",
      "[Epoch 2] Running Loss: 1.3998826344807942\n",
      "[Epoch 2] Validation Loss: 1.6535897731781006\n",
      "[Epoch 3] Running Loss: 1.32309803697798\n",
      "[Epoch 3] Validation Loss: 1.518499732017517\n",
      "[Epoch 4] Running Loss: 1.259595062997606\n",
      "[Epoch 4] Validation Loss: 1.3146004915237426\n",
      "[Epoch 5] Running Loss: 1.2014122936460707\n",
      "[Epoch 5] Validation Loss: 1.0613124132156373\n",
      "[Epoch 6] Running Loss: 1.1411989794837103\n",
      "[Epoch 6] Validation Loss: 0.8296997785568238\n",
      "[Epoch 7] Running Loss: 1.0726038416226704\n",
      "[Epoch 7] Validation Loss: 0.7126899719238281\n",
      "[Epoch 8] Running Loss: 1.010978513293796\n",
      "[Epoch 8] Validation Loss: 0.6403851985931397\n",
      "[Epoch 9] Running Loss: 0.9480336705843607\n",
      "[Epoch 9] Validation Loss: 0.6141368627548218\n",
      "[Epoch 10] Running Loss: 0.881600923008389\n",
      "[Epoch 10] Validation Loss: 0.5505748748779297\n",
      "[Epoch 11] Running Loss: 0.7807550099160936\n",
      "[Epoch 11] Validation Loss: 0.4528485119342804\n",
      "[Epoch 12] Running Loss: 0.7097637719578214\n",
      "[Epoch 12] Validation Loss: 0.4702981173992157\n",
      "[Epoch 13] Running Loss: 0.6464140547646416\n",
      "[Epoch 13] Validation Loss: 0.531257152557373\n",
      "[Epoch 14] Running Loss: 0.5891677406099107\n",
      "[Epoch 14] Validation Loss: 0.5665771543979645\n",
      "[Epoch 15] Running Loss: 0.5366050369209714\n",
      "[Epoch 15] Validation Loss: 0.5362530052661896\n",
      "[Epoch 16] Running Loss: 0.4899612565835317\n",
      "[Epoch 16] Validation Loss: 0.5791039109230042\n",
      "[Epoch 17] Running Loss: 0.44975128438737655\n",
      "[Epoch 17] Validation Loss: 0.6015400886535645\n",
      "[Epoch 18] Running Loss: 0.41368966632419163\n",
      "[Epoch 18] Validation Loss: 0.48751776814460757\n",
      "[Epoch 19] Running Loss: 0.37880904144710964\n",
      "[Epoch 19] Validation Loss: 0.4660660266876221\n",
      "[Epoch 20] Running Loss: 0.3470589882797665\n",
      "[Epoch 20] Validation Loss: 0.3893983900547028\n",
      "[Epoch 21] Running Loss: 0.32226622104644775\n",
      "[Epoch 21] Validation Loss: 0.3953990817070007\n",
      "[Epoch 22] Running Loss: 0.2999584939744737\n",
      "[Epoch 22] Validation Loss: 0.42511492371559145\n",
      "[Epoch 23] Running Loss: 0.28221311502986485\n",
      "[Epoch 23] Validation Loss: 0.44545972943305967\n",
      "[Epoch 24] Running Loss: 0.2667247686121199\n",
      "[Epoch 24] Validation Loss: 0.3926673650741577\n",
      "[Epoch 25] Running Loss: 0.2520192977454927\n",
      "[Epoch 25] Validation Loss: 0.3823039889335632\n",
      "[Epoch 26] Running Loss: 0.24052919116285112\n",
      "[Epoch 26] Validation Loss: 0.393314391374588\n",
      "[Epoch 27] Running Loss: 0.22996469835440317\n",
      "[Epoch 27] Validation Loss: 0.37096128463745115\n",
      "[Epoch 28] Running Loss: 0.2203199863433838\n",
      "[Epoch 28] Validation Loss: 0.3620655477046967\n",
      "[Epoch 29] Running Loss: 0.21191820667849648\n",
      "[Epoch 29] Validation Loss: 0.3155805766582489\n",
      "[Epoch 30] Running Loss: 0.20407061775525412\n",
      "[Epoch 30] Validation Loss: 0.30946623384952543\n",
      "[Epoch 31] Running Loss: 0.1974567042456733\n",
      "[Epoch 31] Validation Loss: 0.3279984563589096\n",
      "[Epoch 32] Running Loss: 0.1912565595573849\n",
      "[Epoch 32] Validation Loss: 0.32857811748981475\n",
      "[Epoch 33] Running Loss: 0.1858433104223675\n",
      "[Epoch 33] Validation Loss: 0.2961306691169739\n",
      "[Epoch 34] Running Loss: 0.18133655687173209\n",
      "[Epoch 34] Validation Loss: 0.29082177877426146\n",
      "[Epoch 35] Running Loss: 0.17692681981457603\n",
      "[Epoch 35] Validation Loss: 0.28615238070487975\n",
      "[Epoch 36] Running Loss: 0.1731135348478953\n",
      "[Epoch 36] Validation Loss: 0.27221931219100953\n",
      "[Epoch 37] Running Loss: 0.16942359672652352\n",
      "[Epoch 37] Validation Loss: 0.2775832027196884\n",
      "[Epoch 38] Running Loss: 0.16707292033566368\n",
      "[Epoch 38] Validation Loss: 0.2661910057067871\n",
      "[Epoch 39] Running Loss: 0.16367947227425045\n",
      "[Epoch 39] Validation Loss: 0.2652192682027817\n",
      "[Epoch 40] Running Loss: 0.1612555897898144\n",
      "[Epoch 40] Validation Loss: 0.25282876193523407\n",
      "[Epoch 41] Running Loss: 0.15865181552039254\n",
      "[Epoch 41] Validation Loss: 0.2532850503921509\n",
      "[Epoch 42] Running Loss: 0.15696613325013054\n",
      "[Epoch 42] Validation Loss: 0.24551628530025482\n",
      "[Epoch 43] Running Loss: 0.15442468722661337\n",
      "[Epoch 43] Validation Loss: 0.24872325956821442\n",
      "[Epoch 44] Running Loss: 0.15288717796405157\n",
      "[Epoch 44] Validation Loss: 0.23881882578134536\n",
      "[Epoch 45] Running Loss: 0.1508800056245592\n",
      "[Epoch 45] Validation Loss: 0.24275160133838652\n",
      "[Epoch 46] Running Loss: 0.14922180854611927\n",
      "[Epoch 46] Validation Loss: 0.23821980208158494\n",
      "[Epoch 47] Running Loss: 0.14784504390425152\n",
      "[Epoch 47] Validation Loss: 0.23747337013483047\n",
      "[Epoch 48] Running Loss: 0.14631313499477175\n",
      "[Epoch 48] Validation Loss: 0.23611795902252197\n",
      "[Epoch 49] Running Loss: 0.1449036772052447\n",
      "[Epoch 49] Validation Loss: 0.23793607652187349\n",
      "[Epoch 50] Running Loss: 0.1439385356174575\n",
      "[Epoch 50] Validation Loss: 0.23153474777936936\n",
      "[Epoch 51] Running Loss: 0.14227957609626982\n",
      "[Epoch 51] Validation Loss: 0.23113518059253693\n",
      "[Epoch 52] Running Loss: 0.14140680101182726\n",
      "[Epoch 52] Validation Loss: 0.21665778905153274\n",
      "[Epoch 53] Running Loss: 0.13949582477410635\n",
      "[Epoch 53] Validation Loss: 0.2644496217370033\n",
      "[Epoch 54] Running Loss: 0.13923922263913685\n",
      "[Epoch 54] Validation Loss: 0.23485332131385803\n",
      "[Epoch 55] Running Loss: 0.13757443014118406\n",
      "[Epoch 55] Validation Loss: 0.24342130720615388\n",
      "[Epoch 56] Running Loss: 0.13724431064393786\n",
      "[Epoch 56] Validation Loss: 0.24687354564666747\n",
      "[Epoch 57] Running Loss: 0.13619030598137113\n",
      "[Epoch 57] Validation Loss: 0.22177833318710327\n",
      "[Epoch 58] Running Loss: 0.13472418238719305\n",
      "[Epoch 58] Validation Loss: 0.24688203632831573\n",
      "[Epoch 59] Running Loss: 0.13443585568004185\n",
      "[Epoch 59] Validation Loss: 0.26099260449409484\n",
      "[Epoch 60] Running Loss: 0.13306719892554814\n",
      "[Epoch 60] Validation Loss: 0.24498743712902069\n",
      "[Epoch 61] Running Loss: 0.1324968139330546\n",
      "[Epoch 61] Validation Loss: 0.23432472199201584\n",
      "[Epoch 62] Running Loss: 0.13152945124440724\n",
      "[Epoch 62] Validation Loss: 0.23123500347137452\n",
      "[Epoch 63] Running Loss: 0.13095436327987248\n",
      "[Epoch 63] Validation Loss: 0.2303957849740982\n",
      "[Epoch 64] Running Loss: 0.13004430631796518\n",
      "[Epoch 64] Validation Loss: 0.23376930356025696\n",
      "[Epoch 65] Running Loss: 0.12976289954450396\n",
      "[Epoch 65] Validation Loss: 0.23122479915618896\n",
      "[Epoch 66] Running Loss: 0.12912510997719234\n",
      "[Epoch 66] Validation Loss: 0.2322835087776184\n",
      "[Epoch 67] Running Loss: 0.12835140195157793\n",
      "[Epoch 67] Validation Loss: 0.22640086710453033\n",
      "[Epoch 68] Running Loss: 0.12816820955938762\n",
      "[Epoch 68] Validation Loss: 0.2265327349305153\n",
      "[Epoch 69] Running Loss: 0.12733755426274407\n",
      "[Epoch 69] Validation Loss: 0.22699215412139892\n",
      "[Epoch 70] Running Loss: 0.12670119106769562\n",
      "[Epoch 70] Validation Loss: 0.22311624884605408\n",
      "[Epoch 71] Running Loss: 0.12595883508523306\n",
      "[Epoch 71] Validation Loss: 0.2244574934244156\n",
      "[Epoch 72] Running Loss: 0.12538526786698234\n",
      "[Epoch 72] Validation Loss: 0.22874340713024138\n",
      "[Epoch 73] Running Loss: 0.12548770507176718\n",
      "[Epoch 73] Validation Loss: 0.23039451390504836\n",
      "[Epoch 74] Running Loss: 0.1255059184299575\n",
      "[Epoch 74] Validation Loss: 0.23666745722293853\n",
      "[Epoch 75] Running Loss: 0.12634037931760153\n",
      "[Epoch 75] Validation Loss: 0.223066546022892\n",
      "[Epoch 76] Running Loss: 0.12560665690236622\n",
      "[Epoch 76] Validation Loss: 0.22131232917308807\n",
      "[Epoch 77] Running Loss: 0.12461897979180019\n",
      "[Epoch 77] Validation Loss: 0.22471955716609954\n",
      "[Epoch 78] Running Loss: 0.12342035190926658\n",
      "[Epoch 78] Validation Loss: 0.22046280652284622\n",
      "[Epoch 79] Running Loss: 0.12269622418615553\n",
      "[Epoch 79] Validation Loss: 0.22657306045293807\n",
      "[Epoch 80] Running Loss: 0.1226427952448527\n",
      "[Epoch 80] Validation Loss: 0.22722212821245194\n",
      "[Epoch 81] Running Loss: 0.12194742924637264\n",
      "[Epoch 81] Validation Loss: 0.223906409740448\n",
      "[Epoch 82] Running Loss: 0.12209860814942254\n",
      "[Epoch 82] Validation Loss: 0.21864699572324753\n",
      "[Epoch 83] Running Loss: 0.12187701877620485\n",
      "[Epoch 83] Validation Loss: 0.22160185277462005\n",
      "[Epoch 84] Running Loss: 0.12120884905258815\n",
      "[Epoch 84] Validation Loss: 0.21760333180427552\n",
      "[Epoch 85] Running Loss: 0.12000830554299885\n",
      "[Epoch 85] Validation Loss: 0.23102959543466567\n",
      "[Epoch 86] Running Loss: 0.12079843630393346\n",
      "[Epoch 86] Validation Loss: 0.23645827770233155\n",
      "[Epoch 87] Running Loss: 0.12110458148850335\n",
      "[Epoch 87] Validation Loss: 0.23805548250675201\n",
      "[Epoch 88] Running Loss: 0.12078431000312169\n",
      "[Epoch 88] Validation Loss: 0.2236611008644104\n",
      "[Epoch 89] Running Loss: 0.12100973725318909\n",
      "[Epoch 89] Validation Loss: 0.21039161533117295\n",
      "[Epoch 90] Running Loss: 0.12004684491289987\n",
      "[Epoch 90] Validation Loss: 0.22161449491977692\n",
      "[Epoch 91] Running Loss: 0.11951662186119291\n",
      "[Epoch 91] Validation Loss: 0.23207124769687654\n",
      "[Epoch 92] Running Loss: 0.11963573429319593\n",
      "[Epoch 92] Validation Loss: 0.2333011284470558\n",
      "[Epoch 93] Running Loss: 0.1202640069855584\n",
      "[Epoch 93] Validation Loss: 0.21836475133895875\n",
      "[Epoch 94] Running Loss: 0.11842843807405895\n",
      "[Epoch 94] Validation Loss: 0.24049758166074753\n",
      "[Epoch 95] Running Loss: 0.11807227548625734\n",
      "[Epoch 95] Validation Loss: 0.21844589114189147\n",
      "[Epoch 96] Running Loss: 0.11685168908702002\n",
      "[Epoch 96] Validation Loss: 0.23225246369838715\n",
      "[Epoch 97] Running Loss: 0.118807895316018\n",
      "[Epoch 97] Validation Loss: 0.22603183388710021\n",
      "[Epoch 98] Running Loss: 0.11718920949432585\n",
      "[Epoch 98] Validation Loss: 0.2339562490582466\n",
      "[Epoch 99] Running Loss: 0.11798899289634493\n",
      "[Epoch 99] Validation Loss: 0.21846291273832322\n",
      "[Epoch 100] Running Loss: 0.11611622985866335\n",
      "[Epoch 100] Validation Loss: 0.2339698225259781\n"
     ]
    }
   ],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (batch_coords, batch_feats, batch_labels) in enumerate(train_loader):\n",
    "            \n",
    "            tr_inputs_list = []\n",
    "            tr_labels_list = []\n",
    "        \n",
    "            for i in range(len(batch_coords)):\n",
    "                inputs_sparse = SparseTensor(coords=batch_coords[i], feats=batch_feats[i])\n",
    "                labels_sparse = SparseTensor(coords=batch_coords[i], feats=batch_labels[i])\n",
    "                tr_inputs_list.append(inputs_sparse)\n",
    "                tr_labels_list.append(labels_sparse)\n",
    "            \n",
    "            tr_inputs = sparse_collate(tr_inputs_list).to(device=device)\n",
    "            tr_labels = sparse_collate(tr_labels_list).to(device=device)\n",
    "            \n",
    "            with amp.autocast(enabled=amp_enabled):\n",
    "                tr_outputs = model(tr_inputs)\n",
    "                tr_labelsloss = tr_labels.feats.squeeze(-1)\n",
    "                tr_loss = criterion(tr_outputs.feats, tr_labelsloss)\n",
    "            \n",
    "            running_loss += tr_loss.item()\n",
    "            #print(f'[step {batch_idx + 1}] loss = {loss.item()}')\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(tr_loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "        training_losses.append(running_loss / train_steps)\n",
    "        print(f\"[Epoch {epoch+1}] Running Loss: {running_loss / train_steps}\")\n",
    "    \n",
    "        model.eval()\n",
    "        torchsparse.backends.benchmark = True  # type: ignore\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (batch_coords, batch_feats, batch_labels) in enumerate(val_loader):\n",
    "                \n",
    "                v_inputs_list = []\n",
    "                v_labels_list = []\n",
    "            \n",
    "                for i in range(len(batch_coords)):\n",
    "                    inputs_sparse = SparseTensor(coords=batch_coords[i], feats=batch_feats[i])\n",
    "                    labels_sparse = SparseTensor(coords=batch_coords[i], feats=batch_labels[i])\n",
    "                    v_inputs_list.append(inputs_sparse)\n",
    "                    v_labels_list.append(labels_sparse)\n",
    "            \n",
    "                v_inputs = sparse_collate(v_inputs_list).to(device=device)\n",
    "                v_labels = sparse_collate(v_labels_list).to(device=device)\n",
    "        \n",
    "                n_correct = 0\n",
    "                \n",
    "                with amp.autocast(enabled=True):\n",
    "                    v_outputs = model(v_inputs)\n",
    "                    v_labelsloss = v_labels.feats.squeeze(-1)\n",
    "                    v_loss = criterion(v_outputs.feats, v_labelsloss)\n",
    "                \n",
    "                val_loss += v_loss.item()\n",
    "                \n",
    "        validation_losses.append(val_loss / val_steps)\n",
    "        print(f\"[Epoch {epoch+1}] Validation Loss: {val_loss / val_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57521370-ad5e-4e4d-b944-67294568b4cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ../models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m LOSS_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../loss_data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_lr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m tr_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainloss_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m v_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalloss_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/sparse/lib/python3.8/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sparse/lib/python3.8/site-packages/torch/serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sparse/lib/python3.8/site-packages/torch/serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory ../models does not exist."
     ]
    }
   ],
   "source": [
    "MODEL_PATH = '../models/'\n",
    "LOSS_PATH = '../loss_data/'\n",
    "\n",
    "filename = f\"epochs{num_epochs}_lr{lr}_{datetime_str}.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH + filename)\n",
    "\n",
    "tr_filename = f\"trainloss_{datetime_str}.npy\"\n",
    "v_filename = f\"valloss_{datetime_str}.npy\"\n",
    "np.save(LOSS_PATH + tr_filename, training_losses)\n",
    "np.save(LOSS_PATH + v_filename, validation_losses)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25904f13-d9d8-4959-a3a7-9cd2c50ec3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, training_losses, '-o', label='Training Loss', color='blue')\n",
    "plt.plot(epochs, validation_losses, '-o', label='Validation Loss', color='red')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce32fd5-d0eb-4dbb-b807-72495dcab8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_test = coords_test[0:50]\n",
    "feats_test = feats_test[0:50]\n",
    "labels_test = labels_test[0:50]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "torchsparse.backends.benchmark = True  # type: ignore\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_preds = np.array(all_preds)\n",
    "    \n",
    "    \n",
    "    for batch_idx, (batch_coords, batch_feats, batch_labels) in enumerate(test_loader):\n",
    "        inputs_list = []\n",
    "        labels_list = []\n",
    "    \n",
    "        for i in range(len(batch_coords)):\n",
    "            inputs_sparse = SparseTensor(coords=batch_coords[i], feats=batch_feats[i])\n",
    "            labels_sparse = SparseTensor(coords=batch_coords[i], feats=batch_labels[i])\n",
    "            inputs_list.append(inputs_sparse)\n",
    "            labels_list.append(labels_sparse)\n",
    "    \n",
    "        inputs = sparse_collate(inputs_list).to(device=device)\n",
    "        labels = sparse_collate(labels_list).to(device=device)\n",
    "\n",
    "        n_correct = 0\n",
    "        \n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            \n",
    "            labelsloss = labels.feats.squeeze(-1)\n",
    "            loss = criterion(outputs.feats, labelsloss)\n",
    "            _, predicted = torch.max(outputs.feats, 1)\n",
    "\n",
    "            all_preds = np.concatenate((all_preds, predicted.cpu().numpy()))\n",
    "            n_correct += (predicted == labelsloss).sum().item()\n",
    "\n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(labels_test.reshape(-1), all_preds)\n",
    "    \n",
    "    acc = 100.0 * n_correct / (test_len)\n",
    "    print(f'Accuracy of the model: {acc:.3g} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9256c-f9d9-4b55-9cb2-81376ea2cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(cm.shape[0])  # Assuming all classes are present in your matrix\n",
    "plt.xticks(tick_marks, tick_marks)\n",
    "plt.yticks(tick_marks, tick_marks)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Add the values in the cells of the confusion matrix to the plot\n",
    "thresh = cm.max() / 2\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, cm[i, j],\n",
    "             ha=\"center\", va=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
